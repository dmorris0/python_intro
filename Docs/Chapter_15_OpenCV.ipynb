{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 15: OpenCV\n",
    "\n",
    "**OpenCV** provides many image processing and computer vision tools.  While written in C++, it provides a fairly extensive Python interface, enabling it to be used as a Python toolbox, see: [https://docs.opencv.org/4.5.3/](https://docs.opencv.org/4.5.3/).  Use OpenCV for the many powerful image operations such as segmentation, calibration, warping, and even applying deep neural networks to images.  Plotting is fairly limited, and more powerful plotting is available in Matplotlib, see  [Chapter 16: Matplotlib](Chapter_16_Matplotlib.ipynb).\n",
    "\n",
    "For installation, see [Chapter 13](Chapter_13_Numpy.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Operations with OpenCV\n",
    "\n",
    "OpenCV reads images into Numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "img = cv.imread('.Images/book.png', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have provided the full path from where Python is running to the `book.png` image in this repo.  The `-1` flag reads in raw data without changing the format or number of channels.  You'll need to adjust your path to point to this image from where you are running Python.  Now let's examine the image we just read in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see an output `NoneType`, then `img` was not successfully loaded.  You'll need to adjust the path to the image.  If you want to know the path of where Python is currently running use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\morri\\\\Source\\\\Repos\\\\av\\\\python_intro\\\\Docs'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assume you have adjusted the path and successfully read in the image, and it is a `numpy.ndarray`.  Let's examine its size and the pixel type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 160, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it is a 3D array; the `.shape` is a tuple with array dimension sizes, in this case: (height, width, nchannels).  We can think of an image as three single channel arrays each size (height, width) that are stacked along the third dimension.  The three channels are (blue, green, red), as this is the default format for OpenCV, which differs from the more usual (red, green, blue) format.  Notice the data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.dtype "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type is an unsigned 8-bit type (`uint8`) which stores numbers from 0 to 255 inclusive.  We can extract the 3 components of a sample single pixel as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([212, 187, 143], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[22,28,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can drop the trailing colon to get the same output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([212, 187, 143], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[22,28]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three values are the (blue, green, red) values for that pixel.  Review Numpy [indexing](https://numpy.org/doc/stable/reference/arrays.indexing.html) if this isn't clear.\n",
    "\n",
    "Let's say our goal is to find the horizontal image gradient of the grayscale version of this image.  Here are the steps we would take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgf = img / 255 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This converts to a floating point array and scales to a range of 0 to 1, which is the usual range for floating point images.  It is best to use floating point rather than unsigned integers because the gradient can be negative or could be larger than the maximum `uint8` value of 255.  Operating in `uint8` will result in gradients being clipped.  Confirming our new data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgf.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, convert the image to grayscale with `cvtColor`, which is a general purpose colorspace transformation utility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgf_gray = cv.cvtColor(imgf.astype(np.float32), cv.COLOR_BGR2GRAY)  # Convert 3-channel color to single-channel grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do `help(cv.cvtColor)` you will see that `cvtColor` requires floating-bit arrays be 32-bit, while `img` is 64-bit, so we passed in a 32-bit version of `img`.  This grayscale image is the same size, except with a single channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 160)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgf_gray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's apply a Sobel operator to obtain the image gradient in x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgf_grad_x = cv.Sobel(imgf_gray, cv.CV_32F, 1, 0, ksize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cv.CV_32F` argument says that the provided image is a 32-bit floating point array. To see the meaning of the remaining arguments use: `help(cv.Sobel)`.  \n",
    "\n",
    "Next we'll show how to plot images with OpenCV, but save plotting the gradient image for Matplotlib in [Chapter 16: Matplotlib](Chapter_16_Matplotlib.ipynb) which has more powerful plotting capabilities.\n",
    "\n",
    "## Plotting with OpenCV\n",
    "OpenCV has some graphical display functions including showing images.  For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow('Image',img)\n",
    "cv.waitKey(1)            # This gives code 1 millisecond to actually draw the window and then move on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will show an image in a **separate window** that should look like this:\n",
    "\n",
    "![Image](.Images/show_book.png)\n",
    "\n",
    "Find the window (which might be underneath this document window).  Note, that the window is not being refreshed.  If you want it to be refreshed, you can instead call it no arguments: `cv.waitKey()`, and this will stop code progression until you close the window.  To clear any drawn windows, use:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to draw a circle and rectangle at the image center.  The OpenCV `circle` and `rectangle` functions will actually change the pixel values, so if we want to avoid changing our `img` variable we could make a copy of it just for plotting as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_cp = img.copy()\n",
    "img_cen_xy = (img_cp.shape[1]//2, img_cp.shape[0]//2)  # Integer division and order (x,y) \n",
    "rectangle = img_cen_xy + (40,20)                # (width=40,height=20):  Concatenates 2 tuples to make bounding box: (left,top,width,height) \n",
    "cv.circle( img_cp, img_cen_xy, radius=15, color=(0,0,255), thickness=2 )\n",
    "cv.rectangle( img_cp, rectangle, color=(0,255,0), thickness=2 )\n",
    "cv.imshow('Image with Circle', img_cp)\n",
    "cv.waitKey(1)                                # This gives code 1 millisecond to draw the window and then move on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, find this window to see the output which should look like this:\n",
    "\n",
    "![Image](.Images/book_circle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the pixelation as the circle is part of the image.  Also, notice that `cv.waitKey(1)` is called with a 1-millisecond argument which is sufficient for OpenCV to draw the window and then move on.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masks\n",
    "A common image processing tool is an image mask.  Typically a mask will have size equal in height and width to an image and have a single value per pixel. Let's create a mask that is true for all the pixels whose red component is greater than its blue component: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = img[:,:,2] > img[:,:,0]\n",
    "cv.imshow('Mask of red > blue',mask.astype(np.uint8)*255)\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mask](.Images/mask.png)\n",
    "\n",
    "Here the red channel is `img[:,:,2]` and blue is `img[:,:,0]`.  Its type is `bool`; that is, each value is `True` or `False`.  Notice that to display the mask I converted it to an unsigned 8-bit image and multiplied by 255 so that all values are 0 (black) or 255 (white).  We can see that the mask shape is the same as the image, except with a single channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 160)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masks can be combined using Numpy's logical operations, such as `logical_and`, or alternatively elementwise multiplication of boolean arrays is the same thing as a logical `AND`. Let's say we want a mask where red values are greater than blue and red values are greater than 128.  This can be done with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mask = np.logical_and( img[:,:,2] > img[:,:,0], img[:,:,2] > 128 )\n",
    "cv.imshow('Mask of red > blue',new_mask.astype(np.uint8)*255)\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![New Mask](.Images/new_mask.png)\n",
    "\n",
    "We could apply the mask to the image, namely zero out all the pixels that are `False` in the mask.  Multiplication by the mask and leveraging Numpy broadcasting will do that easily for us.  Note that we first need to convert the mask into a 3D array to match the number of dimensions in the color image.  We can add a single third channel using `mask[:,:,None]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_img = img * new_mask[:,:,None]\n",
    "cv.imshow('Masked Image',masked_img)\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Masked Image](.Images/Masked_Image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to delete the above windows call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected Components\n",
    "The OpenCV function: `cv.connectedComponentsWithStats` is quite useful.  You can find detailed information on its arguments using `help(cv.connectedComponentsWithStats)`.  The following is an example of its use.  First define an 8-bit image with zeros as the background and non-zeros as the components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 0, 1, 1, 1, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nimg = ( np.array([1,1,0,1,1,1])[:,None] * np.array([1,1,0,1,1,1,1,1]) ).astype(np.uint8)\n",
    "nimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find the connected components along with details for each component as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with each pixel assigned a label value:\n",
      "[[1 1 0 2 2 2 2 2]\n",
      " [1 1 0 2 2 2 2 2]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [3 3 0 4 4 4 4 4]\n",
      " [3 3 0 4 4 4 4 4]\n",
      " [3 3 0 4 4 4 4 4]]\n",
      "Label, Bounding Box,  Npix,  Centroid\n",
      "  0      [0 0 8 6]     13    [ 2.923  2.231]\n",
      "  1      [0 0 2 2]      4    [ 0.500  0.500]\n",
      "  2      [3 0 5 2]     10    [ 5.000  0.500]\n",
      "  3      [0 3 2 3]      6    [ 0.500  4.000]\n",
      "  4      [3 3 5 3]     15    [ 5.000  4.000]\n"
     ]
    }
   ],
   "source": [
    "N, label_img, bbn, centroids = cv.connectedComponentsWithStats( nimg )\n",
    "print('Image with each pixel assigned a label value:')\n",
    "print(label_img)\n",
    "print('Label, Bounding Box,  Npix,  Centroid')\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})   # For nice output formatting\n",
    "for i in range(N):\n",
    "    print(f'{i:3}      {bbn[i,:4]}   {bbn[i,4]:4}    {centroids[i,:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input and output arguments for this line are given below:\n",
    "```python\n",
    "N, label_img, bbn, centroids = cv.connectedComponentsWithStats( nimg )\n",
    "```\n",
    "```\n",
    "nimg:       [HxW] Input image in uint8 format with 0 as background pixels\n",
    "N:          Number of discovered connected components\n",
    "label_img:  [HxW] Each pixel is given its connected component label\n",
    "bbn:        [Nx5] Each row: [left,top,width,height,Npix] is bounding box and\n",
    "                  number of pixels in the connected component\n",
    "centroids:  [Nx2] Each row is the centroid for the component\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label values in `label_img` are `[0,...,N-1]` with 0 being the background label.  Notice the connected component with label 0.  I think the background label is always the first row of `bbn` and `centroids`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### [Outline](../README.md), Next: [Chapter 16: Matplotlib](Chapter_16_Matplotlib.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('av')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed23d99e7629678e46c9f970bda0c38dec7963ec4874f3650470081250edafc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
